import json
import os
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from pathlib import Path

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ .env
RAW_DATA_PATH = os.getenv("RAW_DATA_PATH", "data/raw/result.json")
PROCESSED_DIR = Path(os.getenv("PROCESSED_DATA_DIR", "data/processed"))
USER_1_ID = os.getenv("USER_1_ID")
USER_1_NAME = os.getenv("USER_1_NAME", "User1")
USER_1_PROMPT = os.getenv("USER_1_SYSTEM_PROMPT", "You are a helpful assistant.")
USER_2_ID = os.getenv("USER_2_ID")
USER_2_NAME = os.getenv("USER_2_NAME", "User2")
USER_2_PROMPT = os.getenv("USER_2_SYSTEM_PROMPT", "You are a helpful assistant.")
TIMEOUT_SECONDS = int(os.getenv("CONVERSATION_TIMEOUT", 7200)) # 2 —á–∞—Å–∞

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

class TelegramParser:
    def __init__(self, filepath: str):
        self.filepath = filepath
        with open(filepath, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        # –ö–∞—Ä—Ç–∞ ID -> –ò–º—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        self.id_map = {
            f"user{USER_1_ID}": USER_1_NAME,
            f"user{USER_2_ID}": USER_2_NAME
        }

    def _extract_text(self, msg: Dict[str, Any]) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–∂–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Telegram"""
        text_content = ""
        
        # 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è
        if "text" in msg:
            if isinstance(msg["text"], str):
                text_content = msg["text"]
            elif isinstance(msg["text"], list):
                for entity in msg["text"]:
                    if isinstance(entity, str):
                        text_content += entity
                    elif isinstance(entity, dict) and "text" in entity:
                        text_content += entity["text"]

        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞
        media_tag = ""
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º —Ç–∏–ø –º–µ–¥–∏–∞ (–µ—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç, –≤–µ—Ä–Ω–µ—Ç None)
        media_type = msg.get("media_type")

        if media_type == "sticker":
            emoji = msg.get("sticker_emoji", "")
            file_path = msg.get("file", "")
            media_tag = f" [STICKER: {emoji} path={file_path}]"
        
        elif media_type == "video_file":
             media_tag = " [VIDEO_MESSAGE]"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ .get(), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å KeyError
        elif msg.get("photo"):
            media_tag = " [PHOTO]"

        full_text = text_content + media_tag
        return full_text.strip()

    def process_chat(self):
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞:
        1. –ß–∏—Å—Ç–∏—Ç –º—É—Å–æ—Ä.
        2. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –æ–¥–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞, –∏–¥—É—â–∏–µ –ø–æ–¥—Ä—è–¥.
        3. –†–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —Å–µ—Å—Å–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏.
        """
        print(f"üîÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.data.get('name', 'Unknown Chat')}")
        
        cleaned_messages = []
        raw_msgs = self.data.get("messages", [])
        
        if not raw_msgs:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ JSON")
            return

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        buffer_text = []
        last_user_id = None
        last_timestamp = 0
        last_date_str = ""
        
        for msg in raw_msgs:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–Ω–µ –∏–º–µ—é—â–∏–µ from_id)
            if msg["type"] != "message" or "from_id" not in msg:
                continue

            current_user_id = msg["from_id"]
            current_timestamp = int(msg["date_unixtime"])
            text = self._extract_text(msg)
            
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç –∏ –Ω–µ—Ç –º–µ–¥–∏–∞ (–ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ) - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if not text:
                continue

            # –õ–æ–≥–∏–∫–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (Grouping Logic)
            is_same_user = (current_user_id == last_user_id)
            is_small_gap = (current_timestamp - last_timestamp) < 300 # 5 –º–∏–Ω—É—Ç –Ω–∞ —Å–∫–ª–µ–π–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–¥—Ä—è–¥
            
            if is_same_user and is_small_gap:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (—Å–∫–ª–µ–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –∏–ª–∏ \n)
                buffer_text.append(text)
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø–µ
                last_timestamp = current_timestamp 
            else:
                # –ï—Å–ª–∏ —Å–º–µ–Ω–∏–ª—Å—è —é–∑–µ—Ä –∏–ª–∏ –ø—Ä–æ—à–ª–∞ –∫—É—á–∞ –≤—Ä–µ–º–µ–Ω–∏ -> –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±–ª–æ–∫
                if buffer_text and last_user_id:
                    cleaned_messages.append({
                        "role": self.id_map.get(last_user_id, "unknown"),
                        "user_id": last_user_id,
                        "content": "\n".join(buffer_text), # –°–∫–ª–µ–∏–≤–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Å—Ç—Ä–æ–∫–∏
                        "timestamp": last_timestamp,
                        "date": last_date_str
                    })
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –±–ª–æ–∫
                buffer_text = [text]
                last_user_id = current_user_id
                last_timestamp = current_timestamp
                last_date_str = msg["date"]

        # –ù–µ –∑–∞–±—ã–≤–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫—É—Å–æ–∫
        if buffer_text and last_user_id:
            cleaned_messages.append({
                "role": self.id_map.get(last_user_id, "unknown"),
                "user_id": last_user_id,
                "content": "\n".join(buffer_text),
                "timestamp": last_timestamp,
                "date": last_date_str
            })

        print(f"‚úÖ –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(cleaned_messages)}")
        return cleaned_messages

    def export_for_rag(self, messages):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ—Å—Ç–æ–π JSON –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        output_path = PROCESSED_DIR / "chat_history_rag.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(messages, f, ensure_ascii=False, indent=2)
        print(f"üíæ RAG dataset —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")

    def export_for_finetuning(self, messages):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JSONL —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (ChatML —Ñ–æ—Ä–º–∞—Ç).
        –î–µ–ª–∞–µ—Ç –î–í–ê —Ñ–∞–π–ª–∞: 
        1. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –±—ã—Ç—å User1
        2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –±—ã—Ç—å User2
        """
        
        def save_jsonl(target_id: str, system_prompt: str, filename: str):
            data_rows = []
            
            # target_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –∫–∞–∫ –≤ from_id (–Ω–∞–ø—Ä–∏–º–µ—Ä "user12345")
            target_uid_str = f"user{target_id}"
            
            for i in range(len(messages) - 1):
                msg_prev = messages[i]
                msg_next = messages[i+1]
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑—Ä—ã–≤ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ > 2 —á–∞—Å–æ–≤, –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Ç–µ—Ä—è–Ω)
                if (msg_next["timestamp"] - msg_prev["timestamp"]) > TIMEOUT_SECONDS:
                    continue

                # –õ–û–ì–ò–ö–ê –û–ë–£–ß–ï–ù–ò–Ø:
                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞–ø–∏—Å–∞–ª Target, —Ç–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ - —ç—Ç–æ Input (User), –∞ —Å–ª–µ–¥—É—é—â–µ–µ - Output (Assistant)
                if msg_next["user_id"] == target_uid_str:
                    entry = {
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": msg_prev["content"]},
                            {"role": "assistant", "content": msg_next["content"]}
                        ]
                    }
                    data_rows.append(entry)
            
            out_path = PROCESSED_DIR / filename
            with open(out_path, 'w', encoding='utf-8') as f:
                for row in data_rows:
                    f.write(json.dumps(row, ensure_ascii=False) + "\n")
            print(f"üéì Training dataset ({filename}) —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(data_rows)} –ø—Ä–∏–º–µ—Ä–æ–≤")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–ª—è –ü–µ—Ä–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if USER_1_ID:
            save_jsonl(USER_1_ID, USER_1_PROMPT, f"train_{USER_1_NAME}.jsonl")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–ª—è –í—Ç–æ—Ä–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if USER_2_ID:
            save_jsonl(USER_2_ID, USER_2_PROMPT, f"train_{USER_2_NAME}.jsonl")

if __name__ == "__main__":
    if not os.path.exists(RAW_DATA_PATH):
        print(f"‚ùå –§–∞–π–ª {RAW_DATA_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü–æ–ª–æ–∂–∏—Ç–µ result.json –≤ –ø–∞–ø–∫—É data/raw/")
    else:
        parser = TelegramParser(RAW_DATA_PATH)
        processed_msgs = parser.process_chat()
        
        if processed_msgs:
            parser.export_for_rag(processed_msgs)
            parser.export_for_finetuning(processed_msgs)